# Kayak-Big-Data-Project

Block 1 - Build and populate a data management infrastructure

C1.1 - Design a robust and suitable data architecture by creating data lakes and data warehouses to meet the storage, usage, security and protection needs of the organisation defined in the specifications

C1.2 - Integrate the storage and distributed computing dimension into the data infrastructure via the use of tools such as Spark or AWS Redshift in order to adapt it to Big Data management needs   

C1.3 - Collect data from different sources (Web, internal software such as Sage/Excel or external software such as Google Analytics) via programming libraries such as Scrapy or Beautifulsoup in compliance with the user data protection standards defined in the RGPD in order to feed the Data Lake in order to refine the results of future analyses 

C1.4 - Clean and organise the data in the Data Warehouse by writing extraction, transformation and loading (ETL) processes to make the data available and understandable to other business teams. 
